{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling barometric pressure, linear trend, tidal corrections, regional strains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sections in this notebook:\n",
    "\n",
    "&emsp;Introduction <br>\n",
    "&emsp;&emsp;BAYTAP\n",
    "1. Import the necessary modules, data, and metadata <br>\n",
    "   1.1 Select the station you want to analyze <br>\n",
    "   1.2 Load the file into a dataframe <br>\n",
    "   1.3 Download and store the xml metadata <br>\n",
    "1. Barometric pressure correction <br>\n",
    "   2.1 Available pressure channels <br>\n",
    "   2.2 Scale and interpolate the raw pressure data <br>\n",
    "3. Linear trend correction <br>\n",
    "4. Tidal correction <br>\n",
    "   4.1 Model tides in SPOTL <br>\n",
    "   4.2 Load tides to dataframe <br>\n",
    "5. Regional strains <br>\n",
    "6. Saving and plotting the product <br>\n",
    "   6.1 Save the dataframe to text files <br>\n",
    "   6.2 Plot <br>\n",
    "\n",
    "Tips: \n",
    "- If you don't see the cell widget, try running all initialization cells, or the individual cell, and it should pop up. \n",
    "- If at any point you wish to take a look at the dataframe we continually add to, type ```df.head()``` into a new code cell and run it. \n",
    "- If something seems off, make sure you ran prior cells. Some cells have dependencies on the cells before it, even between sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Introduction\n",
    "***\n",
    "\n",
    "The goal of this notebook is to model gauge strain corrections for the barometric pressure response, linear trend, and tides. \n",
    "\n",
    "Although we will not run BAYTAP, describing it will help us to understand predictable responses in the strainmeter data. Once modeled, these corrections can be removed from the linearized strain to produce residual time series - which will highlight anomalous signals of interest. \n",
    "\n",
    "### Time series analysis in BAYTAP08\n",
    "The original BAYTAP-G program was rewritten by Duncan Agnew in the BAYTAP08 iteration: http://igppweb.ucsd.edu/~agnew/Baytap/baytap.html. \n",
    " \n",
    "In sum, the program assumes a strain signal ($y_i$) composed of the following components: \n",
    "\n",
    ">$$y_i = t_i + d_i + c_i + s_i$$\n",
    "- $t_i$: tidal signal\n",
    "- $d_i$: long term trend (instrument drift)\n",
    "- $c_i$: response to other effects (e.g., barometric pressure)\n",
    "- $s_i$: data offsets\n",
    "\n",
    "The tidal signal is composed of the tidal amplitudes and phases we seek ($A_m$ and $B_m$), and the known theoretical tidal group values ($C_{mi}$ and $S_{mi}$) that are the sum of the constituents with similar frequencies:\n",
    ">$$t_i =\\sum_{m=1}^{M} (A_m C_{mi}+B_m S_{mi})$$\n",
    "\n",
    "The barometric response is considered linear with the barometric pressure change. Where, $b_i$ is the barometric response coefficient:\n",
    ">$$c_i=b_i y_i$$\n",
    "\n",
    "The residual time series is left once these signals are removed: \n",
    ">$$ r_i = y_i - (t_i + d_i + c_i + s_i)$$\n",
    "\n",
    "BAYTAP solves for the model parameters by minimizing S:\n",
    ">$$S = \\sum_{i=1}^{N}r_i^2+ D^2 \\sum_{i=1}^{n} (d_i - 2d_{i-1} + d_{i-2})^2 + W^2 \\sum_{m=2}^{M}(A_m - A_{m-1})^2+(B_m-B_{m-1})^2 $$\n",
    "- D is an input smoothness parameter, where a very large D provides a linear drift with time. \n",
    "- W is an input parameter that controls how much the tidal admittance can vary over frequency bands. \n",
    "\n",
    "The strainmeters have already been analyzed with BAYTAP, and those outputs are what we will use to model the tidal correction and the barometric pressure correction. We can find the info in the station metadata.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Import the necessary modules, data, and metadata \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "# This imports matplotlib for later plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Make plotting interactive\n",
    "#%matplotlib notebook\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from scipy import signal, linalg\n",
    "import xmltodict\n",
    "\n",
    "# This imports obspy, a python toolbox for seismology,\n",
    "# the iris web services client, a reader for stream data\n",
    "# and the UTC date time format\n",
    "import obspy\n",
    "from obspy import read, UTCDateTime, read_inventory\n",
    "from obspy.clients.iris import Client\n",
    "client = Client()\n",
    "from obspy.clients.fdsn import Client\n",
    "inv_client = Client('IRIS')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, interact, Layout\n",
    "style = {'description_width': 'initial'}\n",
    "layout=Layout(width='30%', height='40px')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "### 1.1 Select the station you want to analyze\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick the file you would like to model corrections for:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6f6c43f0974b17af5703f58e67fbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Station file:', options=('PB.B916.T0.RS.2009-02-062009-02-22_Level1.txt', 'PB.B916.T0.RSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign station seed codes from selected file\n",
    "\n",
    "dir = './DataFiles/Level1/'\n",
    "sta_list = []\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith('Level1.txt'):\n",
    "        sta_list.append(file)\n",
    "        \n",
    "# Set initial values   \n",
    "file = sta_list[0]\n",
    "network = file[0:2]\n",
    "scode = file[3:7]\n",
    "loc = file[8:10]\n",
    "cha = file[11:13]\n",
    "\n",
    "print('Pick the file you would like to model corrections for:')\n",
    "sta_select = widgets.Dropdown(\n",
    "            options=sta_list,\n",
    "            value=sta_list[0],\n",
    "            description='Station file:',\n",
    "            )\n",
    "# Change the station and network as the dropdown is changed\n",
    "def the_ccodes(siteval):\n",
    "    global scode, network, loc, cha, file\n",
    "    file = siteval\n",
    "    network = siteval[0:2]\n",
    "    scode = siteval[3:7]\n",
    "    loc = siteval[8:10]\n",
    "    cha = siteval[11:13]\n",
    "def on_cselect(change):\n",
    "    the_ccodes(change.new)\n",
    "sta_select.observe(on_cselect,names='value')\n",
    "\n",
    "display(sta_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.2 Load the file into a dataframe\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163d14838af64e42a10baa5079975c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Load dataframe', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c597a22bcd047cb8455424286f2728e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a dataframe with the file and assign start and end dates\n",
    "fbutton = widgets.Button(description=\"Load dataframe\", button_style='danger')\n",
    "foutput = widgets.Output()\n",
    "\n",
    "display(fbutton, foutput)\n",
    "\n",
    "# Initial start and end times (arbitrarily chosen)\n",
    "start = UTCDateTime('2000-01-01 00:00:00.000')\n",
    "end = UTCDateTime('2000-01-02 00:00:00.000')\n",
    "file_list = ['DF not loaded','DF not loaded','DF not loaded','DF not loaded']\n",
    "\n",
    "def on_fbutton_clicked(b):\n",
    "    with foutput:\n",
    "        foutput.clear_output()\n",
    "        global df, start, end, file_list, comment_lines\n",
    "        \n",
    "        # Store file comments\n",
    "        comment_lines = []\n",
    "        with open(dir+file,'r') as f:\n",
    "            for ln in f:\n",
    "                if ln.startswith('#'):\n",
    "                    comment_lines.append('#'+ln[1:])\n",
    "        f.close()\n",
    "        \n",
    "        df = pd.read_csv(dir+file,sep='\\t',index_col=0,header=0,comment='#')\n",
    "        print('Wait for the dataframe to display.')\n",
    "        longscode=df.index.name\n",
    "        ind = []\n",
    "        for i in range(0,len(df)):\n",
    "            ind.append(UTCDateTime(df.index[i]))\n",
    "        df.index = ind\n",
    "        start = df.index[0]\n",
    "        end = df.index[-1]\n",
    "        \n",
    "        # For tide code cell later\n",
    "        file_list = [scode+'.'+cha+'.'+'gauge0tides'+str(start)[0:4]+str(start)[5:7]+str(start)[8:10]+'.txt',\n",
    "                     scode+'.'+cha+'.'+'gauge1tides'+str(start)[0:4]+str(start)[5:7]+str(start)[8:10]+'.txt',\n",
    "                     scode+'.'+cha+'.'+'gauge2tides'+str(start)[0:4]+str(start)[5:7]+str(start)[8:10]+'.txt',\n",
    "                     scode+'.'+cha+'.'+'gauge3tides'+str(start)[0:4]+str(start)[5:7]+str(start)[8:10]+'.txt']\n",
    "\n",
    "        \n",
    "        print(df.head())\n",
    "fbutton.on_click(on_fbutton_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.3 Download and store the xml metadata\n",
    "***\n",
    "We will use the station XML metadata associated with the level 2 processed data from UNAVCO to model the tides and regional strains. \n",
    "\n",
    "The xml file can be found for any station under the processed ASCII link here: https://www.unavco.org/data/strain-seismic/bsm-data/bsm-data.html. The file is updated regularly as more processed data becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b2c660255645c2a931cac8481757b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Download xml metadata', layout=Layout(height='40px', width='30%'), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfafccb34dff480d85fe4a83f16fd45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the level 2 xml metadata and store it in a dictionary-type object\n",
    "\n",
    "xbutton = widgets.Button(description=\"Download xml metadata\",layout=layout, button_style='danger')\n",
    "xoutput = widgets.Output()\n",
    "\n",
    "display(xbutton, xoutput)\n",
    "\n",
    "def on_xbutton_clicked(b):\n",
    "    with xoutput:\n",
    "        xoutput.clear_output()\n",
    "        print('Working on it...')\n",
    "\n",
    "        # Check box to download meta again, only displays if already downloaded\n",
    "        cx = widgets.Checkbox(value=False,\n",
    "            description='Download again?',\n",
    "            disabled=False, style=style,layout=Layout(width='50%')\n",
    "            )\n",
    "     \n",
    "        xml_file = scode +'.xml'\n",
    "        xml_path = 'ftp://bsm.unavco.org/pub/bsm/level2/'+scode+'/'\n",
    "        metadir = './DataFiles/Metadata/'\n",
    "        os.makedirs(metadir, exist_ok=True)\n",
    "        if os.path.exists(metadir+xml_file) == True:\n",
    "            print('You already downloaded the',xml_file,'!')\n",
    "            print('Check the box if you would like to download it again: ')\n",
    "            display(cx)\n",
    "        else:\n",
    "            # Import the necessary libraries to download the file\n",
    "            import shutil\n",
    "            import urllib.request as request\n",
    "            from contextlib import closing\n",
    "            \n",
    "            with closing(request.urlopen(xml_path+xml_file)) as r:\n",
    "                with open(metadir+xml_file, 'wb') as f:\n",
    "                    shutil.copyfileobj(r, f)\n",
    "            print(xml_file, 'has been saved to your', metadir, 'directory')\n",
    "            \n",
    "        xobutton = widgets.Button(description=\"Now load the metadata\",layout=layout, button_style='danger')\n",
    "        xooutput = widgets.Output()\n",
    "\n",
    "        display(xobutton, xooutput)\n",
    "\n",
    "        def on_xbutton_click(b):\n",
    "            with xooutput:\n",
    "                xooutput.clear_output()\n",
    "                # If box is checked, download again\n",
    "                if os.path.exists(metadir+xml_file) == True:\n",
    "                    if cx.value == True:\n",
    "                        import shutil\n",
    "                        import urllib.request as request\n",
    "                        from contextlib import closing\n",
    "                        with closing(request.urlopen(xml_path+xml_file)) as r:\n",
    "                            with open(metadir+xml_file, 'wb') as f:\n",
    "                                shutil.copyfileobj(r, f)\n",
    "                        print(xml_file, 'has been re-saved to your', metadir, 'directory')\n",
    "                global xmldict\n",
    "                xmldict = xmltodict.parse(open(metadir+xml_file).read(),process_namespaces=True)\n",
    "                print('Loaded!')\n",
    "        xobutton.on_click(on_xbutton_click)\n",
    "        \n",
    "xbutton.on_click(on_xbutton_clicked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Barometric pressure correction\n",
    "***\n",
    "The strainmeters are sensitive to changes in barometric pressure. In this section we will correct each gauge with its associated pressure response coefficient from the latest xml metadata. The pressure response coefficients were originally calculated in BAYTAP to produce the level 2 data corrections available from UNAVCO, but will work perfectly for our purposes as well. \n",
    "\n",
    "The barometric response at each gauge is modelled as a linear relationship; so, to remove the response we simply need to subtract the correction from the linearized data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 2.1 Available pressure channels\n",
    "***\n",
    "The strainmeters were each installed with a barometric pressure sensor that returns data at 30 minute intervals. At some of the strainmeters, sensors with higher rate data are available. You can pick which channel you would like to use to compute the barometric pressure correction in this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0d58e9dad24062828d43af32921299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Find Pressure Channels', layout=Layout(height='40px', width='30%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5708d027b9264065b88476adcb2cd472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find available pressure channels\n",
    "\n",
    "abutton = widgets.Button(description=\"Find Pressure Channels\",layout=layout, button_style='danger')\n",
    "aoutput = widgets.Output()\n",
    "\n",
    "display(abutton, aoutput)\n",
    "\n",
    "\n",
    "def on_abutton_click(b):\n",
    "    with aoutput:\n",
    "        aoutput.clear_output()\n",
    "        plt.close()\n",
    "        print('Finding barometric pressure channels...')\n",
    "        \n",
    "        # This should return the LDO and RDO options for pressure data, if they are available.\n",
    "        # One issue is the time references the station time, not the individual sensor time, so if an error\n",
    "        # appears when plotting the data, there may not be data for that time.\n",
    "        inv = inv_client.get_stations(network = network, station = scode, channel= '*DO',level='response',matchtimeseries=True,starttime=start,endtime=end)\n",
    "        \n",
    "        print('...channels found! Click to update the dropdown selection')\n",
    "        print('RDO provides 30 minute data while LDO provides 1sps data, if it is available')\n",
    "        chan = widgets.Dropdown(\n",
    "            options=inv.get_contents()['channels'],\n",
    "            value = inv.get_contents()['channels'][0],\n",
    "            description='Pick a channel from the list:',\n",
    "            ) \n",
    "        if len(inv.get_contents()['channels'][0])==2:\n",
    "            print('yes!')\n",
    "        else:\n",
    "            print('no!')\n",
    "        global baro_channel\n",
    "        # initial value\n",
    "        baro_channel = chan.value[-3:]\n",
    "        \n",
    "        display(chan)\n",
    "        # Change the station and network as the dropdown is changed\n",
    "        def the_codes(chanval):\n",
    "            global baro_channel\n",
    "            baro_channel = chanval[-3:]\n",
    "        def on_select(change):\n",
    "            the_codes(change.new)\n",
    "        chan.observe(on_select,names='value')\n",
    "        \n",
    "        obutton = widgets.Button(description=\"Download and Examine Raw Pressure Data\",layout=Layout(width='40%', height='40px'), button_style='danger')\n",
    "        ooutput = widgets.Output()\n",
    "        \n",
    "        display(obutton, ooutput)\n",
    "        \n",
    "        def on_abutton_clicked(b):\n",
    "            with ooutput:\n",
    "                ooutput.clear_output()\n",
    "                plt.close()\n",
    "                global  baro_loc, baro_meta, sf, baro\n",
    "                baro_meta = inv_client.get_stations(network = network, station = scode,channel=baro_channel, level = 'response')\n",
    "                print(baro_meta[0][0][0],baro_meta[0][0][0].response)\n",
    "                \n",
    "                # Let's get the pressure data, take an initial look, and get the conversion to geophysical units\n",
    "                if baro_channel == 'LDO':\n",
    "                    baro_loc = ''\n",
    "                    # Technically we need to add 1000 to get real units of pressure for LDO\n",
    "                    # but we demean the data so just applying the factor is sufficient\n",
    "                    sf = baro_meta[0][0][0].response.instrument_sensitivity.value\n",
    "                else:\n",
    "                    # The scale factor is a conversion to KPa for RDO, we need millibars\n",
    "                    baro_loc = 'TS'\n",
    "                    sf = baro_meta[0][0][0].response.instrument_sensitivity.value * 10\n",
    "                print('From this, we see the conversion to millibar is:',sf)\n",
    "                print('Loading the pressure data to a plot...')\n",
    "                # Download time series from iris\n",
    "                baro = client.timeseries(network,scode,baro_loc,baro_channel,start,end)\n",
    "                plt.plot(baro[0].times('utcdatetime'),baro[0].data) \n",
    "        obutton.on_click(on_abutton_clicked)\n",
    "\n",
    "abutton.on_click(on_abutton_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 2.2 Scale and interpolate the raw pressure data\n",
    "***\n",
    "This next cell performs three main tasks:\n",
    "1. Apply the appropriate geophysical scale factor found in section 2.1 to the raw pressure data.\n",
    "1. Demean the pressure data. \n",
    "1. Multiply the pressure data by the barometric pressure response coefficient (from the metadata) and interpolate to the times of our strain data. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa9584dc9bd41b081c733f79b43b9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Scale and Calculate Pressure Correction', layout=Layout(height='40pâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbc3135951549cfae695ff76c4a339e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store the pressure data in a dataframe with times interpolated to match the gauge data\n",
    "\n",
    "def interp(df, new_index):\n",
    "    \"\"\"Return a new DataFrame with all columns values interpolated\n",
    "    to the new_index values.\"\"\"\n",
    "    df_out = pd.DataFrame(index=new_index)\n",
    "    df_out.index.name = df.index.name\n",
    "\n",
    "    for colname, col in df.iteritems():\n",
    "        df_out[colname] = np.interp(new_index, df.index, col) # default is a linear interpolation\n",
    "\n",
    "    return df_out\n",
    "\n",
    "cbutton = widgets.Button(description=\"Scale and Calculate Pressure Correction\",layout=Layout(width='40%', height='40px'), button_style='danger')\n",
    "coutput = widgets.Output()\n",
    "\n",
    "display(cbutton, coutput)\n",
    "\n",
    "def on_cbutton_clicked(b):\n",
    "    with coutput:\n",
    "        coutput.clear_output()\n",
    "        print('Working on it...')\n",
    "        global df\n",
    "        fillme = np.array([])\n",
    "        for i in range(0,len(baro)):\n",
    "            p_array = np.append(fillme,baro[i].data)\n",
    "        # first use sf in instrument response info to get milibar \n",
    "        # (check that the above output is in hectopascals, hPa=milibar)\n",
    "        # Note that the setra data requires 1000 to be added after unit conversion for real units, \n",
    "        # but we remove the mean anyway so it doesn't matter\n",
    "        millibar = p_array * sf\n",
    "        # Get the UTC datetimes\n",
    "        empty = np.array([])\n",
    "        for i in range(0,len(baro)):\n",
    "            t = baro[i].times('utcdatetime')\n",
    "            tmpt = np.append(empty, t)\n",
    "        # Demean the data\n",
    "        baro_df = pd.DataFrame(millibar-millibar.mean(),tmpt,columns=['millibar'])\n",
    "        \n",
    "        baro_df = interp(baro_df,df.index)\n",
    "        \n",
    "        # compute the barometric pressure correction \n",
    "        baro_ch = {'0':np.array([]),'1':np.array([]),'2':np.array([]),'3':np.array([])}\n",
    "        # get the channel response from the xml data\n",
    "        for channel in baro_ch:\n",
    "            ch_resp = xmldict['strain_xml']['inst_info']['processing']['bsm_processing_history'][-1]['bsm_processing']['atm_pressure']['apc_g'+channel]\n",
    "            baro_ch[channel] = np.array(baro_df['millibar']*float(ch_resp))\n",
    "            df['baro_ch'+channel] = baro_ch[channel]\n",
    "        print('Done!')\n",
    "cbutton.on_click(on_cbutton_clicked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. Linear trend correction\n",
    "***\n",
    "The long term trend of gauge strain is dominated by compression as the ground closes in on the borehole. In some cases, it is helpful to remove this trend (especially if a full month is used). Here, we compute a simple least squares linear fit to the data after the data has been corrected for barometric pressure. One complication to this simple solution is that any offsets or significant variation in the data (whether real or instrumental in origin) will skew the trend. If this is the case, more rigorous post-processing may be necessary.\n",
    "\n",
    "[Cleanstrain+](https://www.usgs.gov/software/cleanstrain) is a software package (external to these notebooks) that can estimate tidal constituents, pressure admittance, offsets, rate changes and temporally correlated noise in strainmeter data, among other things. For offsets, the times of offsets, averaging window to estimate the offsets, and nature of the offsets (tectonic or instrumental) must be supplied. This is a useful resource if further processing is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18ac3024c06422091ed23af107ce71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Compute Linear Trend', layout=Layout(height='40px', width='30%'), sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd541d7afe049fca10f1125d7b28a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the linear trend by least squares regression\n",
    "# remove the pressure correction first\n",
    "# if there are major offsets in the data, the offsets should be removed first\n",
    "\n",
    "lbutton = widgets.Button(description=\"Compute Linear Trend\",layout=layout, button_style='danger')\n",
    "loutput = widgets.Output()\n",
    "\n",
    "display(lbutton,loutput)\n",
    "\n",
    "def on_lbutton_clicked(b):\n",
    "    with loutput:\n",
    "        loutput.clear_output()\n",
    "        global df\n",
    "        \n",
    "        print('Computing linear trend...')\n",
    "        \n",
    "        trend_ch = {'0':np.array([]),'1':np.array([]),'2':np.array([]),'3':np.array([])}\n",
    "    \n",
    "        # get the least squares linear trend of the data using the scipy 'detrend' function\n",
    "        for channel in trend_ch:\n",
    "            trend = np.array(df['ch'+channel+' [ms]']-df['baro_ch'+channel]) - signal.detrend(np.array(df['ch'+channel+' [ms]']-df['baro_ch'+channel]),type='linear')\n",
    "            trend_ch[channel] = trend\n",
    "            df['trend_ch'+channel] = trend_ch[channel]\n",
    "            \n",
    "        print('Done!')\n",
    "lbutton.on_click(on_lbutton_clicked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. Tidal correction\n",
    "***\n",
    "\n",
    "To model the solid earth tides and ocean loads in one 'tidal correction,' we will use a program called SPOTL [(Some Programs for Ocean Tide Loading)](https://igppweb.ucsd.edu/~agnew/Spotl/spotlmain.html). The relevant module from the program for us is **hartid**. From the man pages: \n",
    "\n",
    "```\n",
    "hartid âˆ’ predicts tides from harmonic constants\n",
    "\n",
    "SYNOPSIS\n",
    "hartid year [day-of-year | month day] hr min sec nterms samp\n",
    "\n",
    "DESCRIPTION\n",
    "Given the â€˜â€˜harmonic constantsâ€™â€™ for a tidal series, hartid computes the predicted tides for a specified time.\n",
    "The harmonic constants (in the format specified below) are read in from the standard input, and the predicted tides written to the standard output. The computation (described in more detail below) infers the\n",
    "value of small constituents from those of larger ones, so only a few are needed to give a good result. The\n",
    "arguments on the command line are:\n",
    "year day hr min sec\n",
    "\n",
    "    The time of the first output value, in Greenwich time (UTC); the date may be given either as day\n",
    "of the year, or as month and day (Gregorian calendar). There are no explicit restrictions on the\n",
    "range of admissable dates, but the relevant formulae for the fundamental tidal arguments will be\n",
    "increasingly inaccurate before 1700.\n",
    "\n",
    "nterms    The number of values to be written out\n",
    "samp    The sample interval, in seconds.\n",
    "```\n",
    "\n",
    "hartid can read from standard input in the following format:\n",
    "```\n",
    "l\n",
    "âˆ’116.455\n",
    " 1âˆ’1 0 0 0 0 7.41000 âˆ’78.0\n",
    " 1 1 0 0 0 0 11.7900 âˆ’94.0\n",
    " ...\n",
    " 2 0 0 0 0 0 16.0600 âˆ’287.0\n",
    "-1\n",
    "```\n",
    "The first line is a lowercase L, the last line is a negative one. The second line is the longitude of the location (W is negative). The remaining lines in the middle are the tidal constituent \"Cartwright\" code followed by the amplitude in nanostrain and phase in degrees. There can be many supplied harmonic constituents, but the program requires at least one diurnal and one semidiurnal constituent. The program then automatically models the signal from other smaller amplitude species within the provided tidal bands. \n",
    "\n",
    "Other packages in SPOTL would allow us to compute and recombine the tidal harmonic constituents, but for now we will use the already computed tidal amplitudes and phases from the metadata of our stations. These amplitudes and phases were originally computed in BAYTAP for the level 2 processed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4.1 Model tides in SPOTL\n",
    "***\n",
    "The code cell in this section produces SPOTL modeled tides in individual text files for each gauge from a print statement with the tide Cartwright codes, amplitudes, and phases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36d91a7fbe44659822316809610a94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Compute SPOTL Tides', layout=Layout(height='40px', width='30%'), stâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32b7b7e04554288bb2e335483cc60a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get tidal amplitudes and phases from the metadata and produce a print statement to run with SPOTL\n",
    "\n",
    "# Directory of SPOTL and directory to store the tidal time series \n",
    "spotl = 'docker run -i spotl hartid'\n",
    "dname = './DataFiles/SpotlTides/'\n",
    "rel_dname = './DataFiles/SpotlTides/'\n",
    "os.makedirs(rel_dname, exist_ok=True)\n",
    "\n",
    "if all([os.path.exists(rel_dname+file_list[0]),os.path.exists(rel_dname+file_list[1]),os.path.exists(rel_dname+file_list[2]),os.path.exists(rel_dname+file_list[3])]) == True:\n",
    "    print('Tide files already exist for this station, channel, and startdate.')\n",
    "    print('To caclulate anyway, click the button. Otherwise, move on to section 4.2.')\n",
    "\n",
    "sbutton = widgets.Button(description=\"Compute SPOTL Tides\",layout=layout, button_style='danger')\n",
    "soutput = widgets.Output()\n",
    "\n",
    "def on_button_clicker(b):\n",
    "    with soutput:\n",
    "        soutput.clear_output()\n",
    "        print('Working on it...')\n",
    "        \n",
    "        global samp, val\n",
    "        # xml metadata starting point\n",
    "        h_stit = xmldict['strain_xml']['inst_info']['processing']['bsm_processing_history'][-1]['bsm_processing']['tidal_parameters']['tide']\n",
    "\n",
    "        start_dt = str(start)[0:4] + ' ' +str(start)[5:7] + ' ' +str(start)[8:10] + ' ' +str(start)[11:13] + ' ' +str(start)[14:16] + ' ' +str(start)[17:19]\n",
    "        val = []\n",
    "        for ch in ['gauge0','gauge1','gauge2','gauge3']:\n",
    "            # Start a formatted print statement to run from the command line \n",
    "            print_str = f'printf \\'l\\\\n{str(baro_meta[0][0][0].longitude)}'\n",
    "            # loop through each constituent present in the metadata\n",
    "            for i in range(0,len(h_stit)):\n",
    "                gauge = h_stit[i]['phz']['@kind']\n",
    "                tide = h_stit[i]['@name']\n",
    "                if ch == gauge and (tide == 'O1' or tide == 'M2' or tide == 'K1' or tide == 'S2' or tide == 'N2' or tide == 'P1'):\n",
    "                    # Separated Cartwright codes for each harmonic constituent in the metadata\n",
    "                    dood = str.split(h_stit[i]['@doodson'])\n",
    "                    one = dood[0]\n",
    "                    two = dood[1]\n",
    "                    three = dood[2]\n",
    "                    four = dood[3]\n",
    "                    five = dood[4]\n",
    "                    six = dood[5]\n",
    "                    # Amplitude and phase\n",
    "                    amp = h_stit[i]['amp']['#text']\n",
    "                    phz = h_stit[i]['phz']['#text']\n",
    "                    # Create strings with the correct code, amplitude, and phase\n",
    "                    if tide == 'O1':\n",
    "                        O1 = f'{one:>2}{two:>2}{three:>2}{four:>2}{five:>2}{six:>2} {amp:0<7} {phz:<8}'\n",
    "                        print_str = print_str + f'\\\\n{O1}'\n",
    "                    if tide == 'M2':\n",
    "                        M2 = f'{one:>2}{two:>2}{three:>2}{four:>2}{five:>2}{six:>2} {amp:0<7} {phz:<8}'\n",
    "                        print_str = print_str + f'\\\\n{M2}'\n",
    "                    if tide == 'K1':\n",
    "                        K1 = f'{one:>2}{two:>2}{three:>2}{four:>2}{five:>2}{six:>2} {amp:0<7} {phz:<8}'\n",
    "                        print_str = print_str + f'\\\\n{K1}'\n",
    "                    if tide == 'S2':\n",
    "                        S2 = f'{one:>2}{two:>2}{three:>2}{four:>2}{five:>2}{six:>2} {amp:0<7} {phz:<8}'\n",
    "                        print_str = print_str + f'\\\\n{S2}'\n",
    "                    if tide == 'N2':\n",
    "                        N2 = f'{one:>2}{two:>2}{three:>2}{four:>2}{five:>2}{six:>2} {amp:0<7} {phz:<8}'\n",
    "                        print_str = print_str + f'\\\\n{N2}'\n",
    "                    if tide == 'P1':\n",
    "                        P1 = f'{one:>2}{two:>2}{three:>2}{four:>2}{five:>2}{six:>2} {amp:0<7} {phz:<8}'\n",
    "                        print_str = print_str + f'\\\\n{P1}' \n",
    "            fname = f'{scode}.{cha}.{ch}tides{str(start)[0:4]}{str(start)[5:7]}{str(start)[8:10]}.txt'   \n",
    "            # SPOTL will only allow up to 999999 values to be calculated\n",
    "            # if the dataframe is longer than this, we will have to modify the number of \n",
    "            # samples and sample interval\n",
    "            if len(df) > 999999:\n",
    "                nterms = 999999\n",
    "            else:\n",
    "                nterms = len(df)\n",
    "            samp = round((end-start)/(nterms-2))\n",
    "            # Finish the print statement\n",
    "            print_str = print_str + f'\\\\n-1\\' | {spotl} {start_dt} {nterms} {samp} > {dname}{fname} \\n'\n",
    "            # Run in SPOTL\n",
    "            print(print_str)\n",
    "            os.system(\"%s\" % (print_str))\n",
    "            # Make sure the files wrote\n",
    "            if int(os.popen('wc -l '+dname+fname).read().split(  )[0]) > 0:\n",
    "                print(ch+' tides saved to '+rel_dname)\n",
    "            else: \n",
    "                print('The '+ch+' tides were not computed.')\n",
    "sbutton.on_click(on_button_clicker)\n",
    "\n",
    "display(sbutton, soutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4.2 Load tides to dataframe\n",
    "***\n",
    "\n",
    "This cell loads the SPOTL tides to the dataframe, interpolating values if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1895835cf5fe44f78685ed04454ed1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Load Tidal Corrections to DataFrame', layout=Layout(height='40px', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae59176ff404ababfdda36fa0da5eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tides, and store in the dataframe\n",
    "\n",
    "tbutton = widgets.Button(description=\"Load Tidal Corrections to DataFrame\",layout=Layout(width='40%', height='40px'), button_style='danger')\n",
    "toutput = widgets.Output()\n",
    "\n",
    "def on_tbutton_click(b):\n",
    "    with toutput:\n",
    "        toutput.clear_output()\n",
    "        print('Working on it...')\n",
    "        global df\n",
    "        tide = {'0':None,'1':None,'2':None,'3':None}\n",
    "        for file in os.listdir('./DataFiles/SpotlTides'): \n",
    "            if file.startswith(f'{scode}.{cha}.gauge') and file.endswith(f'{str(start)[0:4]}{str(start)[5:7]}{str(start)[8:10]}.txt'):\n",
    "                n = file[13:14]\n",
    "                tmpdf = pd.read_csv('./DataFiles/SpotlTides/'+file,header=None)\n",
    "                # if the dataframe is longer than 999999, interpolate the tides to the dataframe times\n",
    "                if len(df) > 999999:\n",
    "                    ind = []\n",
    "                    for i in range(0,999998):\n",
    "                        ind.append(start + (samp)*i)\n",
    "                    tmpdf.index = ind\n",
    "                    tide[n] = interp(tmpdf,df.index)\n",
    "                else: \n",
    "                    tide[n] = tmpdf.values\n",
    "                \n",
    "        df['tide_ch0'] = tide['0']/1000\n",
    "        df['tide_ch1'] = tide['1']/1000\n",
    "        df['tide_ch2'] = tide['2']/1000\n",
    "        df['tide_ch3'] = tide['3']/1000\n",
    "        print('Done!')\n",
    "tbutton.on_click(on_tbutton_click)\n",
    "\n",
    "display(tbutton, toutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. Regional strains\n",
    "***\n",
    "In this section, we will apply the orientation matrix ($a^{-1}_{ij}$) to transform the gauge strains into regional areal and shear strains ($E_j$). Two orientation matrices may exist for the strainmeters: (1) The manufacturer's orientation matrix, and (2) the tidally calibrated matrix. See Hodgkinson et al. (2013) for more information on the calibration methods. We will start by using the latest orientation matrix in the xml metadata. \n",
    "\n",
    "Generally, each gauge strain ($e_i$) can be expressed as a linear combination of the areal and shear strains multiplied by coefficients derived from instrument orientation and instrument-bedrock coupling information. This is:\n",
    ">$$e_{i} = a_{i1}E_A + a_{i2}E_D + a_{i3}E_S $$\n",
    "\n",
    "Where the coupling coefficients ($a_{ij}$) can be determined through calibration with a known physical event (e.g. the tides, seismic waves), or by assuming constrained instrument properties. In the latter case, the manufacturer's coupling coefficients ($c_i$ for areal coupling, $d_i$ for shear coupling), and gauge orientations ($\\theta_i$) are used to create the orientation matrix. With these estimated quantities for one gauge, the equation above becomes: \n",
    ">$$e_{i} = 0.5[c_{i}E_A + d_{i}cos(2\\theta_i)E_D + d_{i}sin(2\\theta_i)E_S] $$\n",
    "\n",
    "Whether determined by calibration with known geophysical events or by assuming instrument coupling and orientation, we can apply the inverse of the orientation matrix (note that it is the Moore-Penrose Pseudoinverse) to the measured gauge strain as follows:\n",
    "\n",
    ">$$a^{-1}_{ij} e_{i} = E_{j}$$ <br>\n",
    ">$$\\begin{pmatrix} a_{11} & a_{12} & a_{13} & a_{14} \\\\ a_{21} & a_{22} & a_{23} & a_{24} \\\\ a_{31} & a_{32} & a_{33} & a_{34} \\end{pmatrix}^{-1} \\begin{pmatrix} e_{0} \\\\ e_{1} \\\\ e_{2} \\\\ e_{3} \\end{pmatrix} = \\begin{pmatrix} e_{EE} + e_{NN} \\\\ e_{EE} - e_{NN} \\\\ 2e_{EN} \\end{pmatrix} = \\begin{pmatrix} E_A \\\\ E_D \\\\ E_S \\end{pmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tip: if you know one of you gauges has bad data, and you don't want that to appear in your regional strains, exclude it now.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d22c7b64c849b2a4db981b2a0c089f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Gauges to exclude:', options={'ch0': 0, 'ch1': 1, 'ch2': 2, 'ch3': 3}, style=Descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3392599b07e24926be2f83b9f5f6ef5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Get Orientation Matrix', layout=Layout(height='40px', width='30%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fadc2e752344ffa8e5143d8cef88816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to apply the orientation matrix to gauge data\n",
    "# Get the orientation matrix from the latest xml metadata entry\n",
    "def regional_s(z,y,x,w):\n",
    "    '''\n",
    "    A function that takes 4 dataframe type columns (strain) and applies the orientation matrix to produce areal and shear strains.\n",
    "    ''' \n",
    "    EA = []\n",
    "    ED = []\n",
    "    ES = []\n",
    "    for i in range(0,len(df)): \n",
    "        gauge_strain = np.array([z.iloc[i],y.iloc[i],x.iloc[i],w.iloc[i]])\n",
    "        Ei = np.matmul(a_inv,gauge_strain)\n",
    "        EA.append(Ei[0])\n",
    "        ED.append(Ei[1])\n",
    "        ES.append(Ei[2])\n",
    "    return EA, ED, ES\n",
    "\n",
    "print('Tip: if you know one of you gauges has bad data, and you don\\'t want that to appear in your regional strains, exclude it now.')\n",
    "\n",
    "exclude = {'ch0':0,'ch1':1,'ch2':2,'ch3':3}\n",
    "exc = widgets.SelectMultiple(\n",
    "    options=exclude,\n",
    "    description='Gauges to exclude:',\n",
    "    disabled=False, style=style\n",
    "    )\n",
    "\n",
    "display(exc)\n",
    "\n",
    "ibutton = widgets.Button(description=\"Get Orientation Matrix\",layout=layout, button_style='danger')\n",
    "ioutput = widgets.Output()\n",
    "\n",
    "def on_ibutton_clicked(b):\n",
    "    with ioutput:\n",
    "        ioutput.clear_output()\n",
    "        print('Working on it...')\n",
    "        global a_inv\n",
    "        # The orientation matrix from the xml metadata\n",
    "        a_loc = xmldict['strain_xml']['inst_info']['processing']['bsm_processing_history'][-1]['bsm_processing']['orientation_matrix']\n",
    "        c = 1.5; d = 3.0\n",
    "        a1 = np.array([c*float(a_loc['o11']),d*float(a_loc['o12']),d*float(a_loc['o13'])])\n",
    "        a2 = np.array([c*float(a_loc['o21']),d*float(a_loc['o22']),d*float(a_loc['o23'])])\n",
    "        a3 = np.array([c*float(a_loc['o31']),d*float(a_loc['o32']),d*float(a_loc['o33'])])\n",
    "        a4 = np.array([c*float(a_loc['o41']),d*float(a_loc['o42']),d*float(a_loc['o43'])])\n",
    "        a_mat = np.array([a1,a2,a3,a4])\n",
    "        \n",
    "        # Compute the Moore-Penrose pseudo inverse matrix with SciPy linalg module\n",
    "        a_inv = linalg.pinv(a_mat)\n",
    "            \n",
    "        # If any gauges are excluded, set their column to 0\n",
    "        if (0 in exc.value) == True:\n",
    "            a_inv[:,0] = [0,0,0]\n",
    "        if (1 in exc.value) == True:\n",
    "            a_inv[:,1] = [0,0,0]\n",
    "        if (2 in exc.value) == True:\n",
    "            a_inv[:,2] = [0,0,0]\n",
    "        if (3 in exc.value) == True:\n",
    "            a_inv[:,3] = [0,0,0]\n",
    "        print(a_inv)\n",
    "        print('Done!')\n",
    "ibutton.on_click(on_ibutton_clicked)\n",
    "\n",
    "display(ibutton, ioutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 6. Saving and plotting the product\n",
    "***\n",
    "Congrats! We can now save and plot the linearized gauge strains, areal and shear strains, and corrections.\n",
    "\n",
    "The first cell produces an option to save what we have calculated in two files: (1) Contains the linearized gauge strain and corrections, (2) contains the areal and shear strains and corrections.\n",
    "\n",
    "The second cell is an interactive plotting option - the second cell is not dependent on the first, so you can plot without saving the files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 6.1 Save the dataframe to text files\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eeb300f0ba42d7a3ff84014fe5e065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Compute and Save Strains', layout=Layout(height='40px', width='30%'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43157f77767e411b8063e508b48b101f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Option to save:\n",
    "# a file with raw gauge strain, pressure correction, tidal correction, and linear trend correction\n",
    "# a file with areal and shear gauge strain, areal and shear tide correction, areal and shear pressure correction, areal and shear linear correction\n",
    "\n",
    "save_button = widgets.Button(description=\"Compute and Save Strains\",layout=layout, button_style='danger')\n",
    "save_output = widgets.Output()\n",
    "\n",
    "display(save_button, save_output)\n",
    "\n",
    "def on_save_button_clicked(b):\n",
    "    with save_output:\n",
    "        save_output.clear_output()\n",
    "        print('Working on it...')\n",
    "        print('will take time with long datadets...')\n",
    "        global moddf\n",
    "        gauge = regional_s(df['ch0 [ms]'],df['ch1 [ms]'],df['ch2 [ms]'],df['ch3 [ms]'])\n",
    "        gaugeEA = gauge[0]\n",
    "        gaugeES = gauge[1]\n",
    "        gaugeED = gauge[2]\n",
    "        baros = regional_s(df['baro_ch0'],df['baro_ch1'],df['baro_ch2'],df['baro_ch3'])\n",
    "        baroEA = baros[0]\n",
    "        baroES = baros[1]\n",
    "        baroED = baros[2]\n",
    "        tide = regional_s(df['tide_ch0'],df['tide_ch1'],df['tide_ch2'],df['tide_ch3'])\n",
    "        tideEA = tide[0]\n",
    "        tideES = tide[1]\n",
    "        tideED = tide[2]\n",
    "        trend = regional_s(df['trend_ch0'],df['trend_ch1'],df['trend_ch2'],df['trend_ch3'])\n",
    "        trendEA = trend[0]\n",
    "        trendES = trend[1]\n",
    "        trendED = trend[2]\n",
    "        cols = np.column_stack([gaugeEA,gaugeED,gaugeES,tideEA,tideED,tideES,baroEA,baroED,baroES,trendEA,trendED,trendES])\n",
    "        moddf = pd.DataFrame(cols,df.index,columns=['gaugeEA','gaugeED','gaugeES','tideEA','tideED','tideES','baroEA','baroED','baroES','trendEA','trendED','trendES'])\n",
    "        \n",
    "        chkf = widgets.Checkbox(value=False,\n",
    "                description='Save level 2 data files?',\n",
    "                disabled=False, style=style\n",
    "                )\n",
    "        voutput = widgets.Output()\n",
    "        display(chkf,voutput)\n",
    "        def on_checkf(c):\n",
    "            with voutput:\n",
    "                voutput.clear_output()\n",
    "                dir = './DataFiles/Level2/'\n",
    "                os.makedirs(dir, exist_ok=True)\n",
    "                sfile = network + '.' + scode + '.' + loc + '.' + cha + '.' +str(start.date)+'_gauge_strain_and_corrections.txt'\n",
    "                rfile = network + '.' + scode + '.' + loc + '.' + cha + '.' +str(start.date)+'_regional_strain_and_corrections.txt'\n",
    "                with open(dir+rfile,'w') as f:\n",
    "                    if len(exc.value) > 0:\n",
    "                        for i in range(0,len(exc.value)):\n",
    "                            exc_ch = list(exc.options.keys())[list(exc.value)[i]]\n",
    "                            comment = '# '+exc_ch+' excluded in regional strain transformation.\\n'\n",
    "                            f.write(comment)\n",
    "                f.close()\n",
    "                # Write the reference strain values as comment\n",
    "                with open(dir+sfile,'w') as f:\n",
    "                    for val in [0,1,2,3]:\n",
    "                        f.write(comment_lines[val])\n",
    "                f.close()\n",
    "                df.to_csv(dir+sfile,sep='\\t',mode='a')\n",
    "                moddf.to_csv(dir+rfile,sep='\\t',mode='a')\n",
    "                print(sfile+' and '+rfile+' saved to '+dir)\n",
    "        chkf.observe(on_checkf,'value')\n",
    "    \n",
    "save_button.on_click(on_save_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 6.2 Plot\n",
    "***\n",
    "\n",
    "This plotting option performs calculations on the fly for regional strains. Another plotting option is available in NB4 with the files saved in section 6.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c762dfa0b18b4e3e831f340031ee6981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Corrections to apply:', options={'Pressure': 1, 'Linear': 2, 'Tidesâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16a65e0afb04e9e92fc026cdea0b09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Plot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094178eeeeb140c298ef89fa16db0882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive plotting\n",
    "# Correction Options: linearized strain, barometric correction, linear correction, (offset correction?),tidal correction\n",
    "# Plot Options: gauges, regional strains\n",
    "        \n",
    "# Set initial values\n",
    "correct = {'Pressure':1, 'Linear':2, 'Tides':3}\n",
    "A = widgets.SelectMultiple(\n",
    "    options=correct,\n",
    "    description='Corrections to apply:',\n",
    "    disabled=False, style=style\n",
    "    )\n",
    "\n",
    "plot = {'ch0':0, 'ch1':1, 'ch2':2, 'ch3':3, 'Areal':4,'Differential Shear':5,'Engineering Shear':6}\n",
    "B = widgets.SelectMultiple(\n",
    "    options=plot,\n",
    "    description='Plot:',\n",
    "    disabled=False, style=style\n",
    "    )\n",
    "plot_corr = {'Pressure Correction':1,'Modelled Tides':2,'Linear Trend':3}\n",
    "C = widgets.SelectMultiple(\n",
    "    options=plot_corr,\n",
    "    description='Include Correction:',\n",
    "    disabled=False, style=style\n",
    "    )\n",
    "display(HBox([A,B,C]))\n",
    "pbutton = widgets.Button(description=\"Plot\", button_style='danger')\n",
    "poutput = widgets.Output()\n",
    "\n",
    "def on_pbutton_clicking(but):\n",
    "    with poutput:\n",
    "        poutput.clear_output()\n",
    "        print('Working on it...')\n",
    "        plt.close()\n",
    "        cor_ch = {'0':None,'1':None,'2':None,'3':None}\n",
    "        for ch in cor_ch:\n",
    "            if (1 in A.value) == True:\n",
    "                p = 1\n",
    "            else:\n",
    "                p = 0\n",
    "            if (2 in A.value) == True:\n",
    "                l = 1\n",
    "            else:\n",
    "                l = 0\n",
    "            if (3 in A.value) == True: \n",
    "                t = 1\n",
    "            else: t = 0\n",
    "            # Corrected gauge data\n",
    "            cor_ch[ch] = df['ch'+ch+' [ms]'] - df['baro_ch'+ch] * p - df['trend_ch'+ch] * l - df['tide_ch'+ch] * t\n",
    "        # Nice time for plotting\n",
    "        plt.close()\n",
    "        xtime = (df.index - df.index[0])/60/60/24\n",
    "        # if areal and/or shears are selected, apply orientation matrix\n",
    "        if (4 in B.value) == True or (5 in B.value) == True or (6 in B.value) == True:  \n",
    "            reg = regional_s(cor_ch['0'],cor_ch['1'],cor_ch['2'],cor_ch['3'])\n",
    "            if (4 in B.value) == True: plt.plot(xtime,reg[0],label='Areal')\n",
    "            if (5 in B.value) == True: plt.plot(xtime,reg[1],label='Differential Shear')\n",
    "            if (6 in B.value) == True: plt.plot(xtime,reg[2],label='Engineering Shear')\n",
    "        # if gauges are selected, plot gauge strain\n",
    "        if (0 in B.value) == True: plt.plot(xtime,cor_ch['0'],label='ch0')\n",
    "        if (1 in B.value) == True: plt.plot(xtime,cor_ch['1'],label='ch1')\n",
    "        if (2 in B.value) == True: plt.plot(xtime,cor_ch['2'],label='ch2')\n",
    "        if (3 in B.value) == True: plt.plot(xtime,cor_ch['3'],label='ch3')\n",
    "        # if corrections are selected, plot the corrections\n",
    "        correction = []\n",
    "        for i in [1,2,3]:\n",
    "            if (1 in C.value) == True:\n",
    "                correction.append('baro')\n",
    "            else:\n",
    "                correction.append(0)\n",
    "            if (2 in C.value) == True:\n",
    "                correction.append('tide')\n",
    "            else:\n",
    "                correction.append(0)\n",
    "            if (3 in C.value) == True:\n",
    "                correction.append('trend')\n",
    "            else:\n",
    "                correction.append(0)\n",
    "            if correction[i] != 0:\n",
    "                if 0 in B.value: plt.plot(xtime,df[correction[i]+'_ch0'],label='ch0 '+correction[i]) \n",
    "                if 1 in B.value: plt.plot(xtime,df[correction[i]+'_ch1'],label='ch1 '+correction[i]) \n",
    "                if 2 in B.value: plt.plot(xtime,df[correction[i]+'_ch2'],label='ch2 '+correction[i]) \n",
    "                if 3 in B.value: plt.plot(xtime,df[correction[i]+'_ch3'],label='ch3 '+correction[i]) \n",
    "                if 4 in B.value: plt.plot(xtime,moddf[correction[i]+'EA'],label='EA '+correction[i])\n",
    "                if 5 in B.value: plt.plot(xtime,moddf[correction[i]+'ED'],label='ED '+correction[i])\n",
    "                if 6 in B.value: plt.plot(xtime,moddf[correction[i]+'ES'],label='ES '+correction[i])\n",
    "        plt.legend()\n",
    "        plt.title(scode+' strain')\n",
    "        plt.xlabel('Days from '+str(start)[0:10]+' '+str(start)[11:19])\n",
    "        plt.ylabel('Microstrain')\n",
    "        plt.show()\n",
    "pbutton.on_click(on_pbutton_clicking)\n",
    "\n",
    "display(pbutton, poutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Agnew, D. C. (2012). SPOTL: Some Programs for Ocean-Tide Loading, SIO Technical Report, Scripps Institution of Oceanography. From https://igppweb.ucsd.edu/~agnew/Spotl/spotlmain.html\n",
    "\n",
    "Hodgkinson, K., J. Langbein, B. Henderson, D. Mencin, and A. Borsa (2013), Tidal calibration of plate boundary observatory borehole strainmeters, J. Geophys. Res. Solid Earth, 118, 447â€“458, doi:10.1029/2012JB009651.\n",
    "\n",
    "Tamura, Y., & Agnew, D. C. (2008). Baytap08 User's Manual. UC San Diego: Library â€“ Scripps Digital Collection. From https://escholarship.org/uc/item/4c27740c"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
